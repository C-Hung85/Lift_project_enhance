#!/usr/bin/env python3
"""
ç–‘ä¼¼é›œè¨Šç–Šåœ–é©—è­‰å·¥å…·

ç”¨æ–¼å”åŠ©æª¢è¦–äººå·¥æ ¡æ­£ï¼ˆmc*.csvï¼‰å¾Œä»æ®˜ç•™çš„å°å¹…é‹å‹•ç¾¤é›†ï¼Œ
é€éå…©éšæ®µç–Šåœ–æ³•ç¢ºèªç¾¤é›†æ˜¯å¦ç‚ºç´”é›œè¨Šï¼Œä¸¦å¯ç›´æ¥å°‡å…¶æ¸…é›¶ã€‚
"""

import sys
import os
from pathlib import Path
from dataclasses import dataclass
from typing import List, Optional, Tuple

import tkinter as tk
from tkinter import ttk, messagebox, filedialog

import cv2
import numpy as np

# å°‡ src ç›®éŒ„åŠ å…¥è·¯å¾‘ä»¥å¾©ç”¨äººå·¥æ ¡æ­£å·¥å…·çš„æ¨¡çµ„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from manual_correction_tool import (  # type: ignore  # pylint: disable=wrong-import-position
    DataManager,
    JPGHandler,
)


@dataclass
class SuspiciousCluster:
    """ç–‘ä¼¼é›œè¨Šç¾¤é›†æè¿°"""

    cluster_index: int                     # åœ¨ DataManager.clusters ä¸­çš„ç´¢å¼•
    non_zero_count: int                    # éé›¶é»æ•¸
    span_rows: int                         # ç¾¤é›†è¦†è“‹çš„åˆ—æ•¸
    max_abs_value: float                   # æœ€å¤§ä½ç§»çµ•å°å€¼
    total_abs_value: float                 # ä½ç§»çµ•å°å€¼ç¸½å’Œ


def derive_video_filename(csv_path: Path) -> str:
    """
    ç”± mc*.csv æ¨å°å½±ç‰‡æª”åï¼ˆç¶­æŒèˆ‡äººå·¥æ ¡æ­£å·¥å…·ç›¸åŒçš„å‘½åè¦å‰‡ï¼‰
    """
    name = csv_path.name
    if name.startswith("mc"):
        base_name = name[2:]
    else:
        base_name = name
    return Path(base_name).with_suffix(".mp4").name


def find_suspicious_clusters(data_manager: DataManager) -> List[SuspiciousCluster]:
    """
    æƒæè³‡æ–™å°‹æ‰¾ç–‘ä¼¼é›œè¨Šç¾¤é›†

    è¦å‰‡ï¼š
        1. ç¾¤é›†éé›¶é»æ•¸ â‰¤ 3
        2. è‹¥ç¾¤é›†æ©«è·¨ 4 å€‹ï¼ˆå«ï¼‰ä»¥ä¸Šè³‡æ–™åˆ—å‰‡æ’é™¤
        3. è‹¥ä»»ä¸€é»çš„ä½ç§» < 0.1mm æˆ–ç¾¤é›†ç¸½ä½ç§» < 0.2mm å‰‡è¦–ç‚ºç–‘ä¼¼
    """
    suspicious: List[SuspiciousCluster] = []

    for idx, cluster in enumerate(data_manager.clusters):
        physical = getattr(cluster, "physical_cluster", None)
        if physical is None:
            continue

        # å–å¾—éé›¶ä½ç§»å€¼
        values: List[float] = []
        for row_index in range(cluster.start_index, cluster.end_index + 1):
            value = data_manager.df.iloc[row_index, data_manager.displacement_col_index]
            if value != 0:
                values.append(float(value))

        if not values:
            continue  # å·²è¢«æ¸…é›¶

        non_zero_count = len(values)
        if non_zero_count > 3:
            continue

        span_rows = cluster.end_index - cluster.start_index + 1
        if span_rows >= 4:
            continue

        abs_values = [abs(v) for v in values]
        max_abs_value = max(abs_values)
        total_abs_value = sum(abs_values)

        one_pixel_mm = one_pixel_in_mm(data_manager.scale_factor)

        if (
            max_abs_value < 0.1
            or total_abs_value <= one_pixel_mm
            or any(v < 0.1 for v in abs_values)
        ):
            suspicious.append(
                SuspiciousCluster(
                    cluster_index=idx,
                    non_zero_count=non_zero_count,
                    span_rows=span_rows,
                    max_abs_value=max_abs_value,
                    total_abs_value=total_abs_value,
                )
            )

    return suspicious


def translate_image(image: np.ndarray, shift: Tuple[float, float]) -> np.ndarray:
    """
    å°‡å½±åƒå¹³ç§»æŒ‡å®šçš„ (dx, dy)ï¼ˆæ”¯æ´äºåƒç´ ä½ç§»ï¼‰
    """
    dx, dy = shift
    height, width = image.shape[:2]
    matrix = np.float32([[1, 0, dx], [0, 1, dy]])
    shifted = cv2.warpAffine(
        image,
        matrix,
        (width, height),
        flags=cv2.INTER_LINEAR,
        borderMode=cv2.BORDER_REFLECT,
    )
    return shifted


def one_pixel_in_mm(scale_factor: float) -> float:
    """è¨ˆç®—ç›¸ç•¶æ–¼ 1 åƒç´ çš„å¯¦éš›è·é›¢ (mm)"""
    if scale_factor == 0:
        return 0.0
    return 10.0 / scale_factor


def compute_contrast_score(
    base: np.ndarray, overlay: np.ndarray, mask: Optional[np.ndarray] = None
) -> float:
    """
    è¨ˆç®—ç–Šåœ–å°æ¯”æŒ‡æ¨™ï¼ˆæ¡ç”¨æ­¸ä¸€åŒ–äº’ç›¸é—œï¼‰
    è¿”å›å€¼ä»‹æ–¼ [-1, 1]ï¼Œè¶Šæ¥è¿‘ 1 ä»£è¡¨æ··åˆå¾Œå°é½Šç¨‹åº¦è¶Šé«˜ã€‚
    """
    if base.size == 0 or overlay.size == 0:
        return 0.0

    base_gray = cv2.cvtColor(base, cv2.COLOR_BGR2GRAY).astype(np.float32)
    overlay_gray = cv2.cvtColor(overlay, cv2.COLOR_BGR2GRAY).astype(np.float32)

    if mask is not None:
        if mask.shape != base_gray.shape:
            raise ValueError("é®ç½©å°ºå¯¸é ˆèˆ‡å½±åƒç›¸åŒ")
        mask = mask.astype(bool)
        base_values = base_gray[mask]
        overlay_values = overlay_gray[mask]
    else:
        base_values = base_gray.reshape(-1)
        overlay_values = overlay_gray.reshape(-1)

    if base_values.size == 0 or overlay_values.size == 0:
        return 0.0

    base_mean = base_values.mean()
    overlay_mean = overlay_values.mean()

    base_centered = base_values - base_mean
    overlay_centered = overlay_values - overlay_mean

    numerator = float(np.sum(base_centered * overlay_centered))
    denominator = float(
        np.sqrt(np.sum(base_centered ** 2) * np.sum(overlay_centered ** 2))
    )
    if denominator == 0:
        return 0.0
    return numerator / denominator


class OverlayCleanupApp:
    """ç–Šåœ–æª¢è¦–èˆ‡é›œè¨Šæ¸…ç† GUI"""

    def __init__(
        self,
        root: tk.Tk,
        data_manager: DataManager,
        jpg_handler: JPGHandler,
        suspicious_clusters: List[SuspiciousCluster],
    ):
        self.root = root
        self.data_manager = data_manager
        self.jpg_handler = jpg_handler
        self.suspicious_clusters = suspicious_clusters

        # ä»‹é¢ç‹€æ…‹
        self.current_index = 0
        self.phase = "roi_selection"  # roi_selection, global_alignment, split_line, split_alignment, decision

        # åœ–åƒè³‡æ–™
        self.pre_frame: Optional[np.ndarray] = None
        self.post_frame: Optional[np.ndarray] = None
        self.roi_rect: Optional[Tuple[int, int, int, int]] = None
        self.roi_pre: Optional[np.ndarray] = None
        self.roi_post: Optional[np.ndarray] = None
        self.current_overlay: Optional[np.ndarray] = None

        # å¹³ç§»åƒæ•¸
        self.global_shift = np.array([0.0, 0.0], dtype=np.float32)
        self.right_shift = np.array([0.0, 0.0], dtype=np.float32)
        self.split_line_points_roi: List[Tuple[float, float]] = []
        self.split_line_preview_roi: Optional[Tuple[float, float]] = None
        self.split_mask: Optional[np.ndarray] = None

        # å°æ¯”è¿½è¹¤
        self.global_contrast_best: Optional[float] = None
        self.global_contrast_current: Optional[float] = None
        self.split_contrast_best_left: Optional[float] = None
        self.split_contrast_best_right: Optional[float] = None
        self.split_contrast_current_left: Optional[float] = None
        self.split_contrast_current_right: Optional[float] = None
        self.latest_measured_mm: Optional[float] = None
        self.latest_csv_mm: Optional[float] = None

        # Tk çµ„ä»¶
        self.setup_ui()
        self.bind_events()

        # ç”¨æ–¼ç•«å¸ƒå¯è¦–åŒ–
        self.canvas_image = None
        self.canvas_bounds = (0, 0, 0, 0)
        self.canvas_rect_id: Optional[int] = None
        self.display_scale = 1.0
        self.drag_start: Optional[Tuple[int, int]] = None

        self.load_next_cluster()

    # ------------------------------------------------------------------ #
    # UI å»ºç½®
    # ------------------------------------------------------------------ #
    def setup_ui(self):
        self.root.deiconify()
        self.root.title("ç–Šåœ–æ¸…ç†å·¥å…· - è¼‰å…¥ä¸­...")
        self.root.geometry("1280x900")

        info_frame = ttk.Frame(self.root)
        info_frame.pack(fill=tk.X, padx=6, pady=4)

        self.info_label = ttk.Label(info_frame, text="", font=("Arial", 10))
        self.info_label.pack(side=tk.LEFT)

        self.status_label = ttk.Label(info_frame, text="", font=("Arial", 10))
        self.status_label.pack(side=tk.RIGHT)

        self.canvas = tk.Canvas(self.root, bg="black", cursor="cross")
        self.canvas.pack(fill=tk.BOTH, expand=True, padx=8, pady=8)

        help_frame = ttk.Frame(self.root)
        help_frame.pack(fill=tk.X, padx=6, pady=4)

        help_text = (
            "æ“ä½œæç¤ºï¼šROIå®Œæˆå¾ŒæŒ‰ Enter é€²å…¥ç–Šåœ–ï¼›"
            "å¹³ç§»éµ q/w/e/r=Â±10px, a/s/d/f=Â±1px, z/x/c/v=Â±0.5pxï¼›"
            "L é–‹å•Ÿåˆ‡å‰²ç·šï¼›Enter å®Œæˆï¼›M æ¨™è¨˜é›œè¨Šï¼›U æ›´æ–°ç–Šåœ–ä½ç§»ï¼›K ä¿ç•™ï¼›B è¿”å›ROIã€‚"
        )
        ttk.Label(help_frame, text=help_text, font=("Arial", 9)).pack(side=tk.LEFT)

    def bind_events(self):
        self.canvas.bind("<Button-1>", self.on_canvas_click)
        self.canvas.bind("<B1-Motion>", self.on_canvas_drag)
        self.canvas.bind("<ButtonRelease-1>", self.on_canvas_release)
        self.root.bind("<Key>", self.on_key_press)
        self.root.focus_set()

    # ------------------------------------------------------------------ #
    # äº‹ä»¶è™•ç†
    # ------------------------------------------------------------------ #
    def on_canvas_click(self, event):
        if self.phase == "roi_selection":
            self.drag_start = (event.x, event.y)
        elif self.phase == "split_line":
            self.handle_split_line_click(event.x, event.y)

    def on_canvas_drag(self, event):
        if self.phase == "roi_selection" and self.drag_start:
            if self.canvas_rect_id:
                self.canvas.delete(self.canvas_rect_id)

            x1, y1 = self.drag_start
            x2, y2 = event.x, event.y

            left, right = sorted([x1, x2])
            top, bottom = sorted([y1, y2])

            self.canvas_rect_id = self.canvas.create_rectangle(
                left, top, right, bottom, outline="red", width=2, dash=(6, 6)
            )
        elif self.phase == "split_line" and self.split_line_points_roi:
            roi_point = self.canvas_to_roi_coordinates(event.x, event.y)
            if roi_point is not None:
                self.split_line_preview_roi = roi_point
                self.draw_split_line()

    def on_canvas_release(self, event):
        if self.phase == "roi_selection" and self.drag_start:
            x1, y1 = self.drag_start
            x2, y2 = event.x, event.y
            self.drag_start = None

            left, right = sorted([x1, x2])
            top, bottom = sorted([y1, y2])

            self.set_roi_from_canvas(left, top, right, bottom)

    def on_key_press(self, event):
        key = event.keysym.lower()

        if key == "return":
            self.handle_enter()
            return
        if key == "b":
            self.reset_to_roi_selection()
            return
        if key == "l":
            self.enter_split_line_mode()
            return
        if key == "escape":
            self.cancel_split_line()
            return
        if key == "m":
            self.mark_current_cluster_as_noise()
            return
        if key == "u":
            self.apply_overlay_measurement()
            return
        if key == "k":
            self.keep_current_cluster()
            return

        if self.phase in {"global_alignment", "split_alignment"}:
            self.handle_translation_key(key)

    # ------------------------------------------------------------------ #
    # éšæ®µåˆ‡æ›
    # ------------------------------------------------------------------ #
    def handle_enter(self):
        if self.phase == "roi_selection":
            if not self.roi_rect:
                messagebox.showwarning("æé†’", "è«‹å…ˆä½¿ç”¨æ»‘é¼ é¸æ“‡ ROIã€‚")
                return
            self.enter_global_alignment()
        elif self.phase == "global_alignment":
            self.enter_decision_phase()
        elif self.phase == "split_alignment":
            self.enter_decision_phase()
        elif self.phase == "decision":
            self.keep_current_cluster()

    def enter_global_alignment(self):
        if not self.prepare_roi():
            return
        self.phase = "global_alignment"
        self.update_overlay_display()
        self.update_status()

    def enter_split_line_mode(self):
        if self.phase != "global_alignment":
            return
        self.phase = "split_line"
        self.split_line_points_roi = []
        self.split_line_preview_roi = None
        self.split_mask = None
        self.canvas.delete("split_line")
        self.update_status("è«‹åœ¨ç•«é¢ä¸Šé»æ“Šå…©é»å»ºç«‹åˆ‡å‰²ç·šã€‚")

    def cancel_split_line(self):
        if self.phase in {"split_line", "split_alignment"}:
            self.phase = "global_alignment"
            self.split_line_points_roi = []
            self.split_line_preview_roi = None
            self.split_mask = None
            self.right_shift = np.array([0.0, 0.0], dtype=np.float32)
            self.canvas.delete("split_line")
            self.update_overlay_display()
            self.update_status()

    def enter_split_alignment(self):
        if len(self.split_line_points_roi) != 2:
            return
        if not self.prepare_split_mask():
            return
        self.phase = "split_alignment"
        self.right_shift = np.array([0.0, 0.0], dtype=np.float32)
        self.split_line_preview_roi = None
        self.split_contrast_best_left = None
        self.split_contrast_best_right = None
        self.update_overlay_display()
        self.update_status()

    def enter_decision_phase(self):
        self.phase = "decision"
        self.latest_measured_mm = self.calculate_measured_displacement_mm()
        self.latest_csv_mm = self.calculate_current_csv_displacement()
        self.update_status()

    def reset_to_roi_selection(self):
        self.phase = "roi_selection"
        self.roi_rect = None
        self.roi_pre = None
        self.roi_post = None
        self.global_shift = np.array([0.0, 0.0], dtype=np.float32)
        self.right_shift = np.array([0.0, 0.0], dtype=np.float32)
        self.split_line_points_roi = []
        self.split_line_preview_roi = None
        self.split_mask = None
        self.global_contrast_best = None
        self.global_contrast_current = None
        self.split_contrast_best_left = None
        self.split_contrast_best_right = None
        self.split_contrast_current_left = None
        self.split_contrast_current_right = None
        self.canvas.delete("split_line")
        self.canvas_rect_id = None
        self.current_overlay = None
        self.latest_measured_mm = None
        self.latest_csv_mm = None
        self.update_canvas_with_frame(self.pre_frame)
        self.update_status("è«‹ä½¿ç”¨æ»‘é¼ æ¡†é¸ ROIï¼Œå®Œæˆå¾ŒæŒ‰ Enterã€‚")

    # ------------------------------------------------------------------ #
    # å¢é›†ç®¡ç†
    # ------------------------------------------------------------------ #
    def load_next_cluster(self):
        if self.current_index >= len(self.suspicious_clusters):
            messagebox.showinfo("å®Œæˆ", "æ²’æœ‰æ›´å¤šç–‘ä¼¼é›œè¨Šç¾¤é›†ã€‚")
            self.save_results_and_exit()
            return

        target = self.suspicious_clusters[self.current_index]
        cluster = self.data_manager.get_cluster(target.cluster_index)
        physical = getattr(cluster, "physical_cluster", None)
        if physical is None:
            self.current_index += 1
            self.load_next_cluster()
            return

        # è¼‰å…¥å°æ‡‰çš„å‰å¾Œ JPG
        pre_jpg = physical.pre_zero_jpg
        post_jpg = physical.post_zero_jpg
        self.pre_frame = self.jpg_handler.load_jpg_frame(pre_jpg)
        self.post_frame = self.jpg_handler.load_jpg_frame(post_jpg)

        if self.pre_frame is None or self.post_frame is None:
            messagebox.showerror(
                "éŒ¯èª¤", f"ç„¡æ³•è¼‰å…¥ç¾¤é›† {physical.cluster_id} çš„å‰å¾Œ JPGã€‚\nè«‹ç¢ºèªæª”æ¡ˆå­˜åœ¨ã€‚"
            )
            self.current_index += 1
            self.load_next_cluster()
            return

        self.root.title(
            f"ç–Šåœ–æ¸…ç†å·¥å…· - ç¾¤é›† {self.current_index + 1}/{len(self.suspicious_clusters)} "
            f"(ID: {physical.cluster_id})"
        )

        pixel_threshold_mm = one_pixel_in_mm(self.data_manager.scale_factor)
        info_text = (
            f"ç¾¤é›† ID {physical.cluster_id} | éé›¶é»æ•¸ {target.non_zero_count} | "
            f"è¡Œæ•¸ {target.span_rows} | max {target.max_abs_value:.3f}mm | "
            f"sum {target.total_abs_value:.3f}mm | 1pxâ‰ˆ{pixel_threshold_mm:.3f}mm"
        )
        self.info_label.config(text=info_text)

        self.reset_to_roi_selection()

    def advance_to_next_cluster(self):
        self.current_index += 1
        self.load_next_cluster()

    # ------------------------------------------------------------------ #
    # ROI èˆ‡ç•«å¸ƒé—œè¯
    # ------------------------------------------------------------------ #
    def set_roi_from_canvas(self, left, top, right, bottom):
        if self.pre_frame is None:
            return

        canvas_x, canvas_y, canvas_w, canvas_h = self.canvas_bounds
        if canvas_w == 0 or canvas_h == 0:
            return

        left = max(canvas_x, left)
        right = min(canvas_x + canvas_w, right)
        top = max(canvas_y, top)
        bottom = min(canvas_y + canvas_h, bottom)

        if right - left < 40 or bottom - top < 40:
            messagebox.showwarning("æé†’", "ROI é¢ç©éå°ï¼Œè«‹é‡æ–°é¸å–ã€‚")
            return

        scale = self.display_scale
        roi_x = int((left - canvas_x) / scale)
        roi_y = int((top - canvas_y) / scale)
        roi_w = int((right - left) / scale)
        roi_h = int((bottom - top) / scale)
        self.roi_rect = (roi_x, roi_y, roi_w, roi_h)
        self.update_status("ROI é¸å–å®Œæˆï¼Œå¯æŒ‰ Enter é€²å…¥ç–Šåœ–ã€‚")

    def prepare_roi(self) -> bool:
        if self.roi_rect is None or self.pre_frame is None or self.post_frame is None:
            return False

        x, y, w, h = self.roi_rect
        self.roi_pre = self.pre_frame[y : y + h, x : x + w]
        self.roi_post = self.post_frame[y : y + h, x : x + w]
        self.global_shift = np.array([0.0, 0.0], dtype=np.float32)
        self.right_shift = np.array([0.0, 0.0], dtype=np.float32)
        self.global_contrast_best = None
        self.global_contrast_current = None
        self.split_contrast_best_left = None
        self.split_contrast_best_right = None
        self.split_contrast_current_left = None
        self.split_contrast_current_right = None
        return True

    def prepare_split_mask(self) -> bool:
        if len(self.split_line_points_roi) != 2 or self.roi_pre is None:
            return False
        (x1, y1), (x2, y2) = self.split_line_points_roi
        height, width = self.roi_pre.shape[:2]
        yy, xx = np.indices((height, width))
        line_dx = x2 - x1
        line_dy = y2 - y1
        cross = (xx - x1) * line_dy - (yy - y1) * line_dx
        self.split_mask = cross <= 0
        return True

    # ------------------------------------------------------------------ #
    # ç•«å¸ƒèˆ‡ç–Šåœ–é¡¯ç¤º
    # ------------------------------------------------------------------ #
    def update_canvas_with_frame(self, frame: Optional[np.ndarray]):
        if frame is None:
            self.canvas.delete("all")
            return
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        self.canvas.update_idletasks()
        canvas_width = max(1, self.canvas.winfo_width())
        canvas_height = max(1, self.canvas.winfo_height())
        h, w = frame_rgb.shape[:2]
        # å…è¨±æ”¾å¤§æœ€å¤š 4 å€ï¼Œä¸”é•·å¯¬ä¸è¶…é 1440 åƒç´ 
        max_scale_limit = min(4.0, 1440.0 / max(w, 1), 1440.0 / max(h, 1))
        scale = min(canvas_width / max(w, 1), canvas_height / max(h, 1), max_scale_limit)
        scale = max(scale, 1e-6)
        new_w = max(1, int(round(w * scale)))
        new_h = max(1, int(round(h * scale)))
        resized = cv2.resize(frame_rgb, (new_w, new_h))

        from PIL import Image, ImageTk

        image = Image.fromarray(resized)
        self.canvas_image = ImageTk.PhotoImage(image)
        self.canvas.delete("all")
        offset_x = (canvas_width - new_w) // 2
        offset_y = (canvas_height - new_h) // 2
        self.canvas.create_image(offset_x, offset_y, anchor=tk.NW, image=self.canvas_image)
        self.canvas_bounds = (offset_x, offset_y, new_w, new_h)
        self.display_scale = scale

    def update_overlay_display(self):
        if self.roi_pre is None or self.roi_post is None:
            return

        shifted_global = translate_image(self.roi_post, tuple(self.global_shift))
        if self.phase == "split_alignment" and self.split_mask is not None:
            shifted_right = translate_image(
                self.roi_post, tuple(self.global_shift + self.right_shift)
            )
            combined = shifted_global.copy()
            combined[~self.split_mask] = shifted_right[~self.split_mask]

            self.split_contrast_current_left = compute_contrast_score(
                self.roi_pre, combined, mask=self.split_mask
            )
            self.split_contrast_current_right = compute_contrast_score(
                self.roi_pre, combined, mask=~self.split_mask
            )

            if (
                self.split_contrast_best_left is None
                or self.split_contrast_current_left > self.split_contrast_best_left
            ):
                self.split_contrast_best_left = self.split_contrast_current_left
            if (
                self.split_contrast_best_right is None
                or self.split_contrast_current_right > self.split_contrast_best_right
            ):
                self.split_contrast_best_right = self.split_contrast_current_right

            overlay = cv2.addWeighted(self.roi_pre, 0.5, combined, 0.5, 0)
        else:
            overlay = cv2.addWeighted(self.roi_pre, 0.5, shifted_global, 0.5, 0)

            self.global_contrast_current = compute_contrast_score(
                self.roi_pre, shifted_global
            )
            if (
                self.global_contrast_best is None
                or self.global_contrast_current > self.global_contrast_best
            ):
                self.global_contrast_best = self.global_contrast_current

        self.current_overlay = overlay
        self.update_canvas_with_frame(overlay)
        self.draw_split_line()
        self.update_status()

    def draw_split_line(self):
        self.canvas.delete("split_line")
        if not self.split_line_points_roi:
            return

        canvas_points: List[Tuple[int, int]] = []
        for roi_point in self.split_line_points_roi:
            converted = self.roi_to_canvas_coordinates(*roi_point)
            if converted is not None:
                canvas_points.append(converted)

        preview_canvas = None
        if self.split_line_preview_roi is not None:
            preview_canvas = self.roi_to_canvas_coordinates(*self.split_line_preview_roi)

        if not canvas_points:
            return

        for x, y in canvas_points:
            self.canvas.create_oval(
                x - 5,
                y - 5,
                x + 5,
                y + 5,
                fill="cyan",
                outline="white",
                width=2,
                tags="split_line",
            )

        if len(canvas_points) >= 2:
            (x1, y1), (x2, y2) = canvas_points[:2]
            self.canvas.create_line(
                x1, y1, x2, y2, fill="yellow", width=2, dash=(4, 4), tags="split_line"
            )
        elif preview_canvas:
            (x1, y1) = canvas_points[0]
            x2, y2 = preview_canvas
            self.canvas.create_line(
                x1, y1, x2, y2, fill="yellow", width=2, dash=(4, 4), tags="split_line"
            )

    # ------------------------------------------------------------------ #
    # ç–Šåœ–äº’å‹•
    # ------------------------------------------------------------------ #
    TRANSLATION_KEYS = {
        "q": np.array([0.0, -10.0], dtype=np.float32),
        "w": np.array([0.0, 10.0], dtype=np.float32),
        "e": np.array([-10.0, 0.0], dtype=np.float32),
        "r": np.array([10.0, 0.0], dtype=np.float32),
        "a": np.array([0.0, -1.0], dtype=np.float32),
        "s": np.array([0.0, 1.0], dtype=np.float32),
        "d": np.array([-1.0, 0.0], dtype=np.float32),
        "f": np.array([1.0, 0.0], dtype=np.float32),
        "z": np.array([0.0, -0.5], dtype=np.float32),
        "x": np.array([0.0, 0.5], dtype=np.float32),
        "c": np.array([-0.5, 0.0], dtype=np.float32),
        "v": np.array([0.5, 0.0], dtype=np.float32),
    }

    def handle_translation_key(self, key: str):
        if key not in self.TRANSLATION_KEYS:
            return
        shift = self.TRANSLATION_KEYS[key]
        if self.phase == "global_alignment":
            self.global_shift += shift
        elif self.phase == "split_alignment":
            self.right_shift += shift
        self.update_overlay_display()

    def handle_split_line_click(self, canvas_x: int, canvas_y: int):
        if self.roi_rect is None:
            return
        roi_point = self.canvas_to_roi_coordinates(canvas_x, canvas_y)
        if roi_point is None:
            return

        if len(self.split_line_points_roi) == 0:
            self.split_line_points_roi.append(roi_point)
            self.split_line_preview_roi = None
            self.draw_split_line()
            self.update_status("è«‹é»é¸ç¬¬äºŒå€‹é»ä»¥å®Œæˆåˆ‡å‰²ç·šã€‚")
        elif len(self.split_line_points_roi) == 1:
            self.split_line_points_roi.append(roi_point)
            self.split_line_preview_roi = None
            self.draw_split_line()
            self.enter_split_alignment()

    # ------------------------------------------------------------------ #
    # ç‹€æ…‹æ›´æ–°
    # ------------------------------------------------------------------ #
    def update_status(self, custom: Optional[str] = None):
        if custom:
            self.status_label.config(text=custom)
            return

        if self.phase == "roi_selection":
            msg = "ROI é¸å–ä¸­ï¼šæ‹–æ›³æ»‘é¼ æ¡†é¸å¾ŒæŒ‰ Enterã€‚"
        elif self.phase == "global_alignment":
            msg = (
                f"å…¨åŸŸç–Šåœ–ï¼šShift=({self.global_shift[0]:.1f}, {self.global_shift[1]:.1f}) "
                f"å°æ¯” {self.global_contrast_current or 0:.4f} / "
                f"{self.global_contrast_best or 0:.4f}ã€‚Enter å®Œæˆï¼ŒL é€²å…¥åˆ‡å‰²ç·šæ¨¡å¼ã€‚"
            )
        elif self.phase == "split_line":
            msg = "åˆ‡å‰²ç·šæ¨¡å¼ï¼šé»æ“Šå…©é»å»ºç«‹åˆ†å‰²ç·šï¼ŒEsc å–æ¶ˆã€‚"
        elif self.phase == "split_alignment":
            msg = (
                f"åˆ†å‰²ç–Šåœ–ï¼šå³å´ Shift=({self.right_shift[0]:.1f}, {self.right_shift[1]:.1f}) "
                f"å·¦å°æ¯” {self.split_contrast_current_left or 0:.4f} / "
                f"{self.split_contrast_best_left or 0:.4f} | å³å°æ¯” {self.split_contrast_current_right or 0:.4f} / "
                f"{self.split_contrast_best_right or 0:.4f}ã€‚Enter å®Œæˆã€‚"
            )
        elif self.phase == "decision":
            measured = self.latest_measured_mm if self.latest_measured_mm is not None else 0.0
            csv_value = self.latest_csv_mm if self.latest_csv_mm is not None else 0.0
            diff = measured - csv_value
            one_pixel_mm = self._get_one_pixel_mm()
            msg = (
                f"æ±ºç­–ï¼šç–Šåœ– {measured:.3f}mm | CSV {csv_value:.3f}mm | å·®å€¼ {diff:+.3f}mm "
                f"| 1pxâ‰ˆ{one_pixel_mm:.3f}mmã€‚"
                " M=æ¸…é›¶ã€U=æ›´æ–°ç–Šåœ–å€¼ï¼ˆéœ€å®Œæˆåˆ‡å‰²ï¼‰ã€K/Enter=ä¿ç•™ã€B=é‡é¸ROIã€‚"
            )
        else:
            msg = ""

        self.status_label.config(text=msg)

    # ------------------------------------------------------------------ #
    # é›œè¨Šåˆ¤å®šèˆ‡å„²å­˜
    # ------------------------------------------------------------------ #
    def mark_current_cluster_as_noise(self):
        if self.phase != "decision":
            return
        target = self.suspicious_clusters[self.current_index]
        self._clear_cluster_values(target.cluster_index)
        messagebox.showinfo("å·²æ¨™è¨˜", "ç¾¤é›†ä½ç§»å·²æ¸…é›¶ã€‚")
        self.export_overlay_image(noise_marked=True)
        self.advance_to_next_cluster()

    def keep_current_cluster(self):
        if self.phase != "decision":
            return
        self.advance_to_next_cluster()

    def calculate_measured_displacement_mm(self) -> float:
        """
        æ ¹æ“šç•¶å‰ç–Šåœ–çµæœæ¨ä¼°ä½ç§»ï¼ˆmmï¼‰ã€‚
        - åˆ†å‰²æ¨¡å¼ï¼šå–å³å´èˆ‡å·¦å´å¹³ç§»é‡å·®ç•°çš„ Y åˆ†é‡ã€‚
        - å…¨åŸŸæ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨å…¨åŸŸå¹³ç§»çš„ Y åˆ†é‡ã€‚
        """
        if self.roi_pre is None:
            return 0.0

        scale_factor = self.data_manager.scale_factor
        if self.split_mask is None or len(self.split_line_points_roi) != 2:
            # æœªé€²å…¥åˆ†å‰²æ¨¡å¼ï¼Œç„¡æ³•å¯é æ¨ä¼°ä½ç§»
            return 0.0

        left_shift = self.global_shift
        right_shift = self.global_shift + self.right_shift
        pixel_value = right_shift[1] - left_shift[1]

        displacement_mm = (pixel_value * 10.0) / scale_factor

        cluster = self.data_manager.get_cluster(self.suspicious_clusters[self.current_index].cluster_index)
        orientation = getattr(cluster, "orientation", 0)
        if orientation in (-1, 1):
            displacement_mm = abs(displacement_mm) * orientation

        return displacement_mm

    def calculate_current_csv_displacement(self) -> float:
        """è¨ˆç®—ç›®å‰ CSV ä¸­è©²ç¾¤é›†çš„ä½ç§»ç¸½å’Œï¼ˆmmï¼‰"""
        target = self.suspicious_clusters[self.current_index]
        cluster = self.data_manager.get_cluster(target.cluster_index)
        values = [
            float(self.data_manager.df.iloc[row_idx, self.data_manager.displacement_col_index])
            for row_idx in range(cluster.start_index, cluster.end_index + 1)
        ]
        return sum(values)

    def apply_overlay_measurement(self):
        """å°‡ç–Šåœ–æ¸¬å¾—çš„ä½ç§»è¦†å¯«è‡³ CSV"""
        if self.phase != "decision":
            return
        if self.latest_measured_mm is None:
            messagebox.showwarning("æç¤º", "å°šæœªå–å¾—ç–Šåœ–ä½ç§»ï¼Œè«‹å…ˆå®Œæˆç–Šåœ–èª¿æ•´ã€‚")
            return
        if self.latest_measured_mm == 0.0:
            messagebox.showwarning("æç¤º", "è«‹å…ˆå»ºç«‹åˆ‡å‰²ç·šä¸¦å®Œæˆç¬¬äºŒéšæ®µå°é½Šå¾Œå†æ›´æ–°ä½ç§»ã€‚")
            return

        target = self.suspicious_clusters[self.current_index]
        one_pixel_mm = self._get_one_pixel_mm()
        if abs(self.latest_measured_mm) <= one_pixel_mm:
            self._clear_cluster_values(target.cluster_index)
            messagebox.showinfo(
                "å·²æ¸…é›¶",
                f"ç–Šåœ–ä½ç§» {self.latest_measured_mm:.3f} mm ä½æ–¼ 1 åƒç´ é–¾å€¼ "
                f"({one_pixel_mm:.3f} mm)ï¼Œå·²è¦–ç‚ºé›œè¨Šä¸¦æ¸…é›¶ã€‚",
            )
            self.export_overlay_image(noise_marked=True)
            self.advance_to_next_cluster()
            return

        applied = self.data_manager.apply_correction(
            target.cluster_index,
            self.latest_measured_mm,
        )
        if applied:
            messagebox.showinfo("å·²æ›´æ–°", f"å·²å¥—ç”¨ç–Šåœ–ä½ç§» {self.latest_measured_mm:.3f} mmã€‚")
        else:
            messagebox.showinfo("æé†’", "ç–Šåœ–ä½ç§»ä½æ–¼é–¾å€¼ï¼Œç¾¤é›†å·²è¦–ç‚ºé›œè¨Šä¸¦æ¸…é›¶ã€‚")
        self.advance_to_next_cluster()

    def export_overlay_image(self, noise_marked: bool):
        if self.current_overlay is None:
            return
        target = self.suspicious_clusters[self.current_index]
        cluster = self.data_manager.get_cluster(target.cluster_index)
        physical = getattr(cluster, "physical_cluster", None)
        if physical is None:
            return

        video_folder = Path("lifts") / "exported_frames" / self.jpg_handler.video_base_name
        video_folder.mkdir(parents=True, exist_ok=True)
        overlay_name = f"static_cluster_{physical.cluster_id:03d}_overlay.png"
        overlay_path = video_folder / overlay_name
        cv2.imwrite(str(overlay_path), self.current_overlay)
        noise_flag = "å·²æ¸…é›¶" if noise_marked else "ä¿ç•™"
        print(f"ğŸ“¸ ç–Šåœ–å¿«ç…§å·²å„²å­˜ï¼š{overlay_path} ({noise_flag})")

    def _clear_cluster_values(self, cluster_index: int):
        """å°‡æŒ‡å®šç¾¤é›†åœ¨ CSV ä¸­çš„ä½ç§»å€¼å…¨éƒ¨æ¸…é›¶"""
        cluster = self.data_manager.get_cluster(cluster_index)
        for row_index in range(cluster.start_index, cluster.end_index + 1):
            self.data_manager.df.iloc[row_index, self.data_manager.displacement_col_index] = 0.0

    def _get_one_pixel_mm(self) -> float:
        """å–å¾—ç›¸ç•¶æ–¼ä¸€å€‹åƒç´ çš„ä½ç§» (mm)"""
        return one_pixel_in_mm(self.data_manager.scale_factor)

    def canvas_to_roi_coordinates(
        self, canvas_x: int, canvas_y: int
    ) -> Optional[Tuple[float, float]]:
        """
        å°‡ç•«å¸ƒåº§æ¨™è½‰æ›ç‚º ROI å…§çš„åƒç´ åº§æ¨™ï¼ˆåƒ…åœ¨ç–Šåœ–éšæ®µä½¿ç”¨ï¼‰
        """
        offset_x, offset_y, width, height = self.canvas_bounds
        if not (
            offset_x <= canvas_x <= offset_x + width
            and offset_y <= canvas_y <= offset_y + height
        ):
            return None
        x = (canvas_x - offset_x) / self.display_scale
        y = (canvas_y - offset_y) / self.display_scale
        return float(x), float(y)

    def roi_to_canvas_coordinates(
        self, roi_x: float, roi_y: float
    ) -> Optional[Tuple[int, int]]:
        """
        å°‡ ROI åƒç´ åº§æ¨™è½‰æ›ç‚ºç•«å¸ƒåº§æ¨™
        """
        offset_x, offset_y, width, height = self.canvas_bounds
        if width == 0 or height == 0:
            return None
        canvas_x = int(offset_x + roi_x * self.display_scale)
        canvas_y = int(offset_y + roi_y * self.display_scale)
        return canvas_x, canvas_y

    def save_results_and_exit(self):
        original_path = Path(self.data_manager.csv_path)
        base_name = original_path.name
        if base_name.startswith("mc"):
            new_name = f"mco{base_name[2:]}"
        else:
            new_name = f"mco{base_name}"
        output_path = original_path.parent / new_name
        self.data_manager.df.to_csv(output_path, index=False)
        messagebox.showinfo("å·²å„²å­˜", f"è™•ç†å®Œæˆï¼Œæª”æ¡ˆå·²å„²å­˜ç‚ºï¼š\n{output_path}")
        self.root.quit()


def main():
    root = tk.Tk()
    root.withdraw()

    try:
        csv_path_str = filedialog.askopenfilename(
            title="é¸æ“‡äººå·¥æ ¡æ­£å¾Œçš„ CSV (mc*.csv)",
            initialdir="lifts/result",
            filetypes=[("CSV æª”æ¡ˆ", "*.csv"), ("æ‰€æœ‰æª”æ¡ˆ", "*.*")],
        )

        if not csv_path_str:
            return

        csv_path = Path(csv_path_str)
        video_filename = derive_video_filename(csv_path)

        try:
            data_manager = DataManager(str(csv_path), video_filename)
        except Exception as exc:  # pylint: disable=broad-except
            messagebox.showerror("éŒ¯èª¤", f"è³‡æ–™è¼‰å…¥å¤±æ•—ï¼š{exc}")
            return

        suspicious = find_suspicious_clusters(data_manager)
        if not suspicious:
            messagebox.showinfo("æç¤º", "æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„ç–‘ä¼¼é›œè¨Šç¾¤é›†ã€‚")
            return

        jpg_handler = JPGHandler(video_filename)

        OverlayCleanupApp(
            root=root,
            data_manager=data_manager,
            jpg_handler=jpg_handler,
            suspicious_clusters=suspicious,
        )

        root.mainloop()
    finally:
        try:
            root.destroy()
        except Exception:
            pass


if __name__ == "__main__":
    main()

