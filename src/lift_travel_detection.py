import os
import sys
os.chdir(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))
sys.path.append("src/")
import cv2
import warnings
import utils
import datetime
import pandas as pd
import numpy as np
from scipy.stats import ttest_1samp
from sklearn.cluster import KMeans
from multiprocessing import Pool
from config import Config, video_config
try:
    from rotation_config import rotation_config
except ImportError:
    # å¦‚æœ rotation_config.py ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºå­—å…¸
    rotation_config = {}
from rotation_utils import rotate_frame

try:
    from darkroom_intervals import darkroom_intervals
except ImportError:
    # å¦‚æœ darkroom_intervals.py ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºå­—å…¸
    darkroom_intervals = {}
from darkroom_utils import get_darkroom_intervals_for_video, is_in_darkroom_interval

def export_frame_jpg(frame_data, jpg_filename, video_name):
    """åŒ¯å‡ºå–®å€‹å¹€ç‚ºJPGï¼ˆæ–¼ exported_frames/<video_name>/ ä¸‹ï¼‰"""
    frame_idx, frame = frame_data

    export_dir = os.path.join('lifts', 'exported_frames', video_name)
    os.makedirs(export_dir, exist_ok=True)

    export_path = os.path.join(export_dir, jpg_filename)
    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 95]
    success = cv2.imwrite(export_path, frame, encode_param)
    if success:
        print(f"ğŸ“¸ åŒ¯å‡ºJPG: {jpg_filename} (frame {frame_idx})")
    else:
        print(f"âŒ åŒ¯å‡ºå¤±æ•—: {jpg_filename}")
    return success

from scale_cache_utils import (
    load_scale_cache, 
    save_scale_cache, 
    is_cache_valid, 
    get_missing_videos,
    print_cache_status,
    generate_scale_images_hash
)

warnings.filterwarnings('ignore')

# Parameters and objects
DATA_FOLDER = Config['files']['data_folder']
feature_detector = cv2.ORB.create(nfeatures=100)
feature_matcher = cv2.BFMatcher.create(normType=cv2.NORM_HAMMING, crossCheck=True)
cluster = KMeans(n_clusters=2, random_state=0)
FRAME_INTERVAL = Config['scan_setting']['interval']
ROI_RATIO = 0.6
# æª¢æ¸¬åƒæ•¸ï¼ˆåƒç´ åŸŸï¼‰
EFFECT_MIN_PX = 1.0
PAIR_TOLERANCE_PX = 1.0
JITTER_MAX_PX = 1.0
EXIT_ZERO_LEN = 3
REVERSAL_PERSIST_R = 2
MIN_MATCHES = 6


# create necessary folders
for folder_name in ['inspection', 'result']:
    os.makedirs(os.path.join(DATA_FOLDER, 'lifts', folder_name), exist_ok=True)

def scan(video_path, file_name):
    vidcap = cv2.VideoCapture(video_path)
    ret, frame = vidcap.read()
    h, w = frame.shape[:2]
    video_length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = vidcap.get(cv2.CAP_PROP_FPS)

    start_frame = int(video_config.get(file_name, {}).get('start', 0) * fps)
    end_frame = int(video_config.get(file_name, {}).get('end', video_length/fps) * fps)
    roi_ratio = video_config.get(file_name, {}).get('roi_ratio', ROI_RATIO)
    
    # å–å¾—æš—æˆ¿æ™‚é–“å€é–“è¨­å®š
    darkroom_intervals_seconds, has_darkroom = get_darkroom_intervals_for_video(file_name, darkroom_intervals)

    # create a mask to define the ROI
    mask = np.zeros((h, w), dtype=np.uint8)
    mask[int(h*roi_ratio/2):int(h*(1-roi_ratio/2)), int(w*roi_ratio/2):int(w*(1-roi_ratio/2))] = 1

    # record container
    result = {
        'frame':[],
        'frame_idx':[],
        'keypoints':[], 
        'camera_pan':[],
        'v_travel_distance':[],
        'kp_pair_lines':[],
        'frame_path':[],
        # è…³æ‰‹æ¶ï¼šä¹‹å¾Œå°‡å¡«å…¥çœŸæ­£çš„ç¾¤é›†è³‡è¨Šï¼›æ­¤éšæ®µå…ˆå›ºå®šç‚º 0/ç©ºå­—ä¸²
        'cluster_id':[],      # ç¾¤å¤–ç‚º 0
        'orientation':[],     # -1/0/+1ï¼›ç¾¤å¤– 0
        'darkroom_event':[]   # 'enter_darkroom' / 'exit_darkroom' / ''
    }

    # ç‹€æ…‹æ©Ÿè®Šæ•¸ï¼ˆç¾¤é›†èˆ‡æŠ–å‹•è™•ç†ï¼Œå…¥ç¾¤å»¶é²ä¸€å¹€ï¼‰
    state = 'Idle'  # Idle / PendingEnter / InCluster
    pending_idx = None
    pending_delta_px = None
    pending_result_idx = None
    current_cluster_id = 0
    physical_cluster_counter = 0
    orientation_current = 0
    zero_streak = 0
    reversal_streak = 0
    # åŒ¯å‡º/å¿«å–è®Šæ•¸
    frame_cache = []                    # æœ€è¿‘è™•ç†å¹€ (frame_idx, frame)
    pending_pre_export = None           # (frame_data, jpg_filename)
    last_non_darkroom_frame = None      # (frame_idx, frame)
    video_name = os.path.splitext(file_name)[0]

    # detect keypoints
    keypoint_list1, feature_descrpitor1 = feature_detector.detectAndCompute(frame, mask)

    # set video to the start point
    vidcap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

    prev_is_darkroom = False

    while ret:
        frame_idx = int(vidcap.get(cv2.CAP_PROP_POS_FRAMES))
        ret, frame = vidcap.read()

        if frame_idx >= end_frame:
            break

        if ret and frame_idx % FRAME_INTERVAL == 0:
            # æª¢æŸ¥æ˜¯å¦éœ€è¦æ—‹è½‰å½±åƒ
            if file_name in rotation_config:
                rotation_angle = rotation_config[file_name]
                frame = rotate_frame(frame, rotation_angle)
            
            keypoint_list2, feature_descrpitor2 = feature_detector.detectAndCompute(frame, mask)

            # default values
            vertical_travel_distance = 0
            camera_pan = False
            display_keypoints = []
            kp_pair_lines = []

            if feature_descrpitor1 is not None and feature_descrpitor2 is not None:
                matches = feature_matcher.match(feature_descrpitor2, feature_descrpitor1)
                paired_keypoints_info_array = []

                for match_info in matches:
                    kp1_idx = match_info.trainIdx
                    kp2_idx = match_info.queryIdx
                    kp1_coord = np.array(keypoint_list1[kp1_idx].pt, dtype=int)
                    kp2_coord = np.array(keypoint_list2[kp2_idx].pt, dtype=int)
                    paired_keypoints_info_array.append([
                        kp2_idx, 
                        kp1_idx, 
                        np.sqrt(np.sum((kp1_coord - kp2_coord)**2)),
                        kp2_coord[0]-kp1_coord[0], # horizontal travel distance
                        kp2_coord[1]-kp1_coord[1], # vertical travel distance
                    ])

                paired_keypoints_info_array = np.array(paired_keypoints_info_array)
                paired_keypoints_info_array = paired_keypoints_info_array[utils.remove_outlier_idx(paired_keypoints_info_array[:, 2], 'upper')]

                if paired_keypoints_info_array.shape[0] >= MIN_MATCHES:
                    
                    display_keypoints = [keypoint_list2[kp2_idx] for kp2_idx in paired_keypoints_info_array[:, 0].astype(int)]
                    kp_pair_lines = [(np.array(keypoint_list1[int(kp1_idx)].pt, dtype=int), np.array(keypoint_list2[int(kp2_idx)].pt, dtype=int)) \
                                     for kp2_idx, kp1_idx in paired_keypoints_info_array[:, :2]]
                    camera_pan = ttest_1samp(paired_keypoints_info_array[:, 3], 0).pvalue < 0.001
                    group_idx_array = cluster.fit_predict(paired_keypoints_info_array[:, 2].reshape(-1, 1))

                    if len(set(group_idx_array)) > 1 and camera_pan == False:
                        group0_v_travel_array = paired_keypoints_info_array[np.where(group_idx_array==0)[0], 4]
                        group1_v_travel_array = paired_keypoints_info_array[np.where(group_idx_array==1)[0], 4]

                        group0_v_travel = np.median(group0_v_travel_array) if ttest_1samp(group0_v_travel_array, 0).pvalue < 0.0001 else 0
                        group1_v_travel = np.median(group1_v_travel_array) if ttest_1samp(group1_v_travel_array, 0).pvalue < 0.0001 else 0

                        if abs(group0_v_travel) > abs(group1_v_travel):
                            vertical_travel_distance = int(group1_v_travel - group0_v_travel)
                        else:
                            vertical_travel_distance = int(group0_v_travel - group1_v_travel)
                    else:
                        vertical_travel_distance = 0
            
            # æª¢æŸ¥æ˜¯å¦åœ¨æš—æˆ¿å€é–“å…§ï¼Œå¦‚æœæ˜¯å‰‡å¿½ç•¥é‹å‹•ï¼ˆé¡ä¼¼ camera panï¼‰
            current_time_seconds = frame_idx / fps
            is_darkroom, darkroom_info = is_in_darkroom_interval(current_time_seconds, darkroom_intervals_seconds)
            
            # å¦‚æœåœ¨æš—æˆ¿å€é–“å…§ï¼Œå°‡é‹å‹•è·é›¢è¨­ç‚º 0ï¼ˆå¿½ç•¥ï¼‰
            if is_darkroom:
                vertical_travel_distance = 0

            # æš—æˆ¿äº‹ä»¶ï¼ˆåƒ…è¨˜éŒ„é€²å‡ºï¼Œä¸æ”¹è®Šé¡¯ç¤ºæ–‡å­—è¡Œç‚ºï¼‰
            if is_darkroom and not prev_is_darkroom:
                darkroom_event = 'enter_darkroom'
            elif (not is_darkroom) and prev_is_darkroom:
                darkroom_event = 'exit_darkroom'
            else:
                darkroom_event = ''
            
            # ç‹€æ…‹æ©Ÿè¨ˆç®—ï¼ˆä»¥åƒç´ åŸŸåˆ¤æ–·å€™é¸ï¼‰
            delta_px = vertical_travel_distance
            is_candidate = (not camera_pan) and (abs(delta_px) >= EFFECT_MIN_PX) and (not is_darkroom)
            effective_mm_current = 0.0

            if is_darkroom:
                # æš—æˆ¿ï¼šå¼·åˆ¶å›åˆ° Idle ç‹€æ…‹ï¼Œä¸ç´¯è¨ˆç¾¤é›†
                if state == 'InCluster':
                    # åœ¨ç¾¤å…§æ™‚é€²å…¥æš—æˆ¿ â†’ å¼·åˆ¶å‡ºç¾¤ï¼Œpost ç”¨æš—æˆ¿å‰æœ€å¾Œä¸€å€‹éæš—æˆ¿å¹€
                    if last_non_darkroom_frame is not None and current_cluster_id:
                        post_name = f'post_cluster_{current_cluster_id:03d}.jpg'
                        export_frame_jpg(last_non_darkroom_frame, post_name, video_name)
                        # å°‡ä¸Šä¸€å¹€çš„ frame_path æ¨™è¨˜ç‚º post
                        if 'frame_path' in result and len(result['frame_path']) > 0:
                            result['frame_path'][-1] = post_name
                    # åŒ¯å‡º preï¼ˆè‹¥å°šæœªåŒ¯å‡ºï¼‰
                    if pending_pre_export is not None:
                        export_frame_jpg(pending_pre_export[0], pending_pre_export[1], video_name)
                        pending_pre_export = None
                state = 'Idle'
                pending_idx = None
                pending_delta_px = None
                pending_result_idx = None
                zero_streak = 0
                reversal_streak = 0
                orientation_current = 0
                current_cluster_id = 0

            elif state == 'Idle':
                zero_streak = 0
                reversal_streak = 0
                if is_candidate:
                    state = 'PendingEnter'
                    pending_idx = frame_idx
                    pending_delta_px = delta_px
                    pending_result_idx = len(result['frame_idx'])  # å°‡åœ¨æœ¬è¿­ä»£æœ«å°¾å¯«å…¥ 0ï¼Œä¹‹å¾Œå†å›å¡«
                # Idle ç‹€æ…‹è¼¸å‡º 0

            elif state == 'PendingEnter':
                if not is_candidate:
                    # ä¸‹ä¸€å¹€ä¸æ˜¯å€™é¸ â†’ è¦–ç‚ºå™ªè²ï¼Œå–æ¶ˆ pending
                    state = 'Idle'
                    pending_idx = None
                    pending_delta_px = None
                    pending_result_idx = None
                else:
                    # æ˜¯å€™é¸ï¼šæª¢æŸ¥ç¬¦è™Ÿé—œä¿‚
                    if np.sign(delta_px) != np.sign(pending_delta_px):
                        # ç›¸åè™Ÿï¼šå…ˆæª¢æŸ¥æ˜¯å¦ç‚ºå¯æŠµéŠ·çš„æ­£è² å°
                        if abs(delta_px + pending_delta_px) <= PAIR_TOLERANCE_PX:
                            # å…¸å‹æ­£è² å° â†’ æŠµéŠ·å¾Œå› Idle
                            state = 'Idle'
                            pending_idx = None
                            pending_delta_px = None
                            pending_result_idx = None
                        else:
                            # é‚Šç•Œç›¸åä½†ä¸æˆå° â†’ å°‡ç•¶å‰å€™é¸æ”¹ç‚ºæ–°çš„ pendingï¼Œç­‰å¾…ä¸‹ä¸€å¹€å†æ±ºå®š
                            pending_idx = frame_idx
                            pending_delta_px = delta_px
                            pending_result_idx = len(result['frame_idx'])
                            # ä¿æŒ PendingEnter ç‹€æ…‹
                    else:
                        # åŒè™Ÿå€™é¸ â†’ ç¢ºèªå…¥ç¾¤ï¼ˆä»¥å‰ä¸€å¹€ pending ç‚ºèµ·é»ï¼‰
                        state = 'InCluster'
                        physical_cluster_counter += 1
                        current_cluster_id = physical_cluster_counter
                        orientation_current = 1 if pending_delta_px > 0 else -1
                        # æ¨™è¨˜ preï¼šå°‡ pending é‚£å¹€çš„ frame_path è¨­ç‚º preï¼Œä¸¦æº–å‚™åŒ¯å‡ºå¿«ç…§
                        pre_name = f'pre_cluster_{current_cluster_id:03d}.jpg'
                        if pending_result_idx is not None and pending_result_idx < len(result['frame_path']):
                            result['frame_path'][pending_result_idx] = pre_name
                        # å¾ frame_cache å–å°æ‡‰å½±æ ¼ï¼ˆå„ªå…ˆ -2ï¼Œå…¶æ¬¡ -1ï¼‰
                        pre_frame = frame_cache[-2] if len(frame_cache) >= 2 else (frame_idx, frame)
                        pending_pre_export = (pre_frame, pre_name)
                        # å›å¡« pending å¹€çš„ mmã€cluster èˆ‡æ–¹å‘
                        if pending_result_idx is not None and pending_result_idx < len(result['v_travel_distance']):
                            scale_factor = video_scale_dict.get(file_name, 1.0)
                            result['v_travel_distance'][pending_result_idx] = pending_delta_px * 10 / scale_factor
                            result['cluster_id'][pending_result_idx] = current_cluster_id
                            result['orientation'][pending_result_idx] = orientation_current
                        pending_idx = None
                        pending_delta_px = None
                        pending_result_idx = None

            elif state == 'InCluster':
                if is_candidate:
                    if np.sign(delta_px) != orientation_current and abs(delta_px) <= JITTER_MAX_PX:
                        # å°å¹…åå‘æŠ–å‹•ï¼šè¦–ç‚º 0ï¼ˆä¸æ”¹ç‹€æ…‹ï¼‰
                        pass
                    elif np.sign(delta_px) != orientation_current:
                        reversal_streak += 1
                        if reversal_streak >= REVERSAL_PERSIST_R:
                            # çœŸåè½‰ï¼šé—œé–‰ç•¶å‰ç¾¤ï¼Œä¸‹ä¸€å¹€å†é‡æ–° Pendingï¼ˆç°¡åŒ–ï¼šå› Idleï¼‰
                            state = 'Idle'
                            current_cluster_id = 0
                            orientation_current = 0
                            reversal_streak = 0
                            zero_streak = 0
                        else:
                            # æš«æ™‚è¦–ç‚º 0
                            pass
                    else:
                        # åŒå‘ï¼šç¶­æŒ
                        reversal_streak = 0
                        zero_streak = 0
                        effective_mm_current = delta_px * 10 / video_scale_dict.get(file_name, 1.0)
                else:
                    zero_streak += 1
                    if zero_streak >= EXIT_ZERO_LEN:
                        # å‡ºç¾¤
                        # åŒ¯å‡º preï¼ˆè‹¥å°šæœªåŒ¯å‡ºï¼‰èˆ‡ post
                        if current_cluster_id:
                            post_name = f'post_cluster_{current_cluster_id:03d}.jpg'
                            export_frame_jpg((frame_idx, frame), post_name, video_name)
                            if pending_pre_export is not None:
                                export_frame_jpg(pending_pre_export[0], pending_pre_export[1], video_name)
                                pending_pre_export = None
                            # è¨˜éŒ„æœ¬å¹€ post æ¨™è¨˜ï¼ˆè¨­ç•¶å‰ç´¢å¼•ï¼‰
                            current_index = len(result['frame_idx'])
                            # æœ¬å¹€ç¨å¾Œæœƒè¢« appendï¼›å› æ­¤å…ˆè¨˜å€‹è®Šæ•¸ï¼Œç¨å¾Œè£œå¯«
                            post_mark_name = post_name
                        else:
                            post_mark_name = ''
                        state = 'Idle'
                        current_cluster_id = 0
                        orientation_current = 0
                        zero_streak = 0
                        reversal_streak = 0
                    else:
                        # ä»åœ¨ç¾¤å…§ä½†æœ¬å¹€ä¸æ˜¯å€™é¸ â†’ è¼¸å‡º 0
                        pass

            # ç¶­è­·å¹€å¿«å–
            frame_cache.append((frame_idx, frame.copy()))
            if len(frame_cache) > 20:
                frame_cache.pop(0)
            if not is_darkroom:
                last_non_darkroom_frame = (frame_idx, frame.copy())

            # å¯«å…¥çµæœï¼ˆç›®å‰ä¸è¨ˆ mm ä½ç§»ç‚º 0 çš„æ¿¾é™¤ï¼Œç¶­æŒåŸè¡Œç‚ºï¼‰
            result['frame'].append(frame)
            result['frame_idx'].append(frame_idx)
            result['keypoints'].append(display_keypoints)
            result['kp_pair_lines'].append(kp_pair_lines)
            result['camera_pan'].append(camera_pan or is_darkroom)  # camera_pan æˆ–æš—æˆ¿å€é–“éƒ½é¡¯ç¤ºç‚º pan
            # æª¢æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ¯”ä¾‹å°ºè³‡æ–™
            if file_name in video_scale_dict:
                scale_factor = video_scale_dict[file_name]
            else:
                print(f"âš ï¸  è­¦å‘Š: å½±ç‰‡ {file_name} æ²’æœ‰æœ‰æ•ˆçš„æ¯”ä¾‹å°ºè³‡æ–™ï¼Œä½¿ç”¨é è¨­å€¼ 1.0")
                scale_factor = 1.0
            # ä¾ç‹€æ…‹è¼¸å‡ºç•¶å‰å¹€çš„æœ‰æ•ˆä½ç§»
            if state == 'InCluster' and effective_mm_current == 0.0 and is_candidate and np.sign(delta_px) == orientation_current:
                effective_mm_current = delta_px * 10 / scale_factor
            result['v_travel_distance'].append(effective_mm_current)
            result['cluster_id'].append(current_cluster_id if state == 'InCluster' else 0)
            result['orientation'].append(orientation_current if state == 'InCluster' else 0)
            # è…³æ‰‹æ¶ï¼šå…ˆå¯«å…¥ç©ºçš„ç¾¤é›†è³‡è¨Šï¼ˆä¹‹å¾Œå¯¦ä½œç‹€æ…‹æ©Ÿå†å¡«å¯¦ï¼‰
            result['darkroom_event'].append(darkroom_event)
            # é è¨­å¡«ç©º frame_path
            result['frame_path'].append('')
            # è‹¥å‰›å‰›æ±ºå®š postï¼ˆå‡ºç¾¤ï¼‰ï¼ŒæŠŠæœ¬å¹€æ¨™è¨˜ç‚º post
            if 'post_mark_name' in locals() and post_mark_name:
                result['frame_path'][-1] = post_mark_name
                del post_mark_name

            keypoint_list1 = keypoint_list2
            feature_descrpitor1 = feature_descrpitor2
            prev_is_darkroom = is_darkroom
    
    # post-process the result
    for idx in range(1, len(result['v_travel_distance'])-1):
        if result['v_travel_distance'][idx] != 0 and (result['v_travel_distance'][idx-1]==0 and result['v_travel_distance'][idx+1]==0):
            result['v_travel_distance'][idx] = 0

    # original video reset to frame 1
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(video_path.replace("data", "inspection"), fourcc, fps/FRAME_INTERVAL, (w, h))

    travel_distance_sum = 0

    for frame, frame_idx, keypoints, kp_pair_lines, camera_pan, vertical_travel_distance, cluster_id_disp, orientation_disp in zip(
        result['frame'], result['frame_idx'], result['keypoints'], result['kp_pair_lines'], result['camera_pan'], result['v_travel_distance'], result['cluster_id'], result['orientation']):
        travel_distance_sum += vertical_travel_distance

        # æª¢æŸ¥ç•¶å‰å¹€æ˜¯å¦åœ¨æš—æˆ¿å€é–“å…§ï¼ˆç”¨æ–¼é¡¯ç¤ºï¼‰
        current_time_seconds = frame_idx / fps
        is_darkroom, _ = is_in_darkroom_interval(current_time_seconds, darkroom_intervals_seconds)

        # draw the display info
        frame = cv2.drawKeypoints(frame, keypoints, None, color=(0, 255, 0), flags=0)
        for coord1, coord2 in kp_pair_lines:
            cv2.line(frame, coord1, coord2, [0, 0, 255], 2)
        
        # æ±ºå®šé¡¯ç¤ºæ–‡å­—å’Œé¡è‰²
        if is_darkroom:
            display_text = "darkroom (ignored)"
            text_color = (128, 128, 128)  # ç°è‰²
        elif camera_pan and not is_darkroom:
            display_text = "camera pan"
            text_color = (0, 255, 255)  # é»ƒè‰²
        else:
            display_text = f"travel: {round(travel_distance_sum, 5)} mm"
            text_color = (0, 0, 255) if vertical_travel_distance == 0 else (0, 255, 0)  # ç´…è‰²/ç¶ è‰²
        
        # é¡¯ç¤º Frame IDï¼ˆç¬¬ä¸€è¡Œï¼‰
        cv2.putText(
            frame,
            f"Frame: {frame_idx}",
            (10, h-110),
            cv2.FONT_HERSHEY_SIMPLEX,
            1,
            (255, 255, 255),
            2)

        # é¡¯ç¤ºæ™‚é–“èˆ‡ç‹€æ…‹ï¼ˆç¬¬äºŒè¡Œï¼‰
        cv2.putText(
            frame, 
            f"{round(frame_idx/fps, 1)} sec  {display_text}", 
            (10, h-80), 
            cv2.FONT_HERSHEY_SIMPLEX, 
            1, 
            text_color, 
            2)

        # é¡¯ç¤ºç¾¤é›†èˆ‡æ–¹å‘ï¼ˆç¬¬ä¸‰è¡Œï¼Œåƒ…åœ¨ç¾¤å…§ï¼‰
        if cluster_id_disp:
            arrow = 'â†‘' if orientation_disp > 0 else ('â†“' if orientation_disp < 0 else '')
            cv2.putText(
                frame,
                f"cluster #{cluster_id_disp} {arrow}",
                (10, h-50),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                (255, 255, 255),
                2)
        
        out.write(frame)
            
    out.release()

    # write down the record
    # æ­£ç¢ºç”Ÿæˆ CSV æª”æ¡ˆè·¯å¾‘
    video_filename = os.path.basename(video_path)  # å–å¾—æª”å (ä¾‹å¦‚: 21.mp4)
    csv_filename = os.path.splitext(video_filename)[0] + ".csv"  # ç§»é™¤å‰¯æª”åä¸¦åŠ ä¸Š .csv (ä¾‹å¦‚: 21.csv)
    csv_path = os.path.join(DATA_FOLDER, 'lifts', 'result', csv_filename)
    
    print(f"ğŸ’¾ å„²å­˜ CSV æª”æ¡ˆ: {csv_path}")
    
    pd.DataFrame({
        'frame_idx':result['frame_idx'],
        'second':[round(i/(fps), 3) for i in result['frame_idx']],
        'vertical_travel_distance (mm)':result['v_travel_distance'],
        'cluster_id':result['cluster_id'],
        'orientation':result['orientation'],
        'darkroom_event':result['darkroom_event'],
        'frame_path':result.get('frame_path', ['']*len(result['frame_idx']))
    }).to_csv(csv_path, index=False)

    print(f"complete: {video_path}")


# æ¯”ä¾‹å°ºè™•ç† - ä½¿ç”¨å¿«å–æ©Ÿåˆ¶
scale_images_dir = os.path.join(DATA_FOLDER, 'lifts', 'scale_images')

print("ğŸ“ è¼‰å…¥æ¯”ä¾‹å°ºå¿«å–...")
scale_cache, cache_info = load_scale_cache()

# æª¢æŸ¥å¿«å–æ˜¯å¦æœ‰æ•ˆ
cache_valid = is_cache_valid(scale_images_dir, cache_info)

# å–å¾—æ‰€æœ‰å½±ç‰‡æª”æ¡ˆ
video_files = []
for root, folder, files in os.walk(os.path.join(DATA_FOLDER, 'lifts', 'data')):
    video_files.extend([f for f in files if f.endswith('.mp4')])

# ç¢ºå®šéœ€è¦è¨ˆç®—æ¯”ä¾‹å°ºçš„å½±ç‰‡
if cache_valid:
    missing_videos = get_missing_videos(scale_cache, video_files)
    print(f"ğŸ“‹ å¿«å–æœ‰æ•ˆï¼Œç™¼ç¾ {len(missing_videos)} å€‹æ–°å½±ç‰‡éœ€è¦è¨ˆç®—æ¯”ä¾‹å°º")
else:
    missing_videos = video_files
    scale_cache = {}
    print("ğŸ”„ å¿«å–ç„¡æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°è¨ˆç®—æ‰€æœ‰æ¯”ä¾‹å°º")

print_cache_status(scale_cache, missing_videos)

# åªè™•ç†éœ€è¦è¨ˆç®—çš„å½±ç‰‡å°æ‡‰çš„æ¯”ä¾‹å°ºåœ–ç‰‡
new_scale_data = {}
for root, folder, files in os.walk(scale_images_dir):
    for file in files:
        video_name = "-".join(file.split(sep="-")[:-1]) + ".mp4"
        
        # åªè™•ç†ç¼ºå°‘å¿«å–çš„å½±ç‰‡
        if video_name not in missing_videos:
            continue
        
        print(f"ğŸ”„ è™•ç†æ¯”ä¾‹å°ºåœ–ç‰‡: {file} (å½±ç‰‡: {video_name})")
        image = cv2.imread(os.path.join(root, file))
        
        # å¾åŸå§‹åœ–ç‰‡ä¸­å°‹æ‰¾ç´…è‰²æ¨™è¨˜é»
        filtered_array = (image[..., 0] < 10) * (image[..., 1] < 10) * (image[..., 2] > 250)
        points = np.where(filtered_array)
        
        # æª¢æŸ¥æ˜¯å¦æ‰¾åˆ°è¶³å¤ çš„ç´…è‰²æ¨™è¨˜é»
        if len(points[0]) < 2:
            image_path = os.path.join(root, file)
            print(f"âŒ æ¯”ä¾‹å°ºéŒ¯èª¤: åœ¨åœ–ç‰‡ '{image_path}' ä¸­æ‰¾ä¸åˆ°è¶³å¤ çš„ç´…è‰²æ¨™è¨˜é»")
            print(f"   å°æ‡‰å½±ç‰‡: {video_name}")
            print(f"   æ‰¾åˆ°ç´…é»æ•¸é‡: {len(points[0])} (éœ€è¦è‡³å°‘ 2 å€‹)")
            print(f"   è«‹æª¢æŸ¥ä¸¦é‡æ–°æ¨™è¨˜ç´…è‰²é»")
            continue
        
        # å–å¾—å…©å€‹ç´…é»çš„åº§æ¨™ (y, x)
        point1_original = (points[0][0], points[1][0])  # (y1, x1)
        point2_original = (points[0][1], points[1][1])  # (y2, x2)
        
        # è¨ˆç®—åŸå§‹æ­æ°è·é›¢ï¼ˆä½œç‚ºé©—ç®—åŸºæº–ï¼‰
        original_euclidean_distance = np.sqrt(
            (point1_original[0] - point2_original[0])**2 + 
            (point1_original[1] - point2_original[1])**2
        )
        
        # è¤‡è£½åº§æ¨™ç”¨æ–¼æ—‹è½‰è¨ˆç®—
        point1 = point1_original
        point2 = point2_original
        
        # å¦‚æœå½±ç‰‡éœ€è¦æ—‹è½‰ï¼Œå°ç´…é»åº§æ¨™é€²è¡Œç›¸æ‡‰çš„æ—‹è½‰è®Šæ›
        if video_name in rotation_config:
            rotation_angle = rotation_config[video_name]
            print(f"  ğŸ”„ æ—‹è½‰æ¯”ä¾‹å°ºåº§æ¨™ (è§’åº¦: {rotation_angle}Â°)")
            
            # å–å¾—åœ–ç‰‡ä¸­å¿ƒé»
            h, w = image.shape[:2]
            center_x, center_y = w // 2, h // 2
            
            # å°‡è§’åº¦è½‰æ›ç‚ºå¼§åº¦
            angle_rad = np.radians(rotation_angle)
            cos_angle = np.cos(angle_rad)
            sin_angle = np.sin(angle_rad)
            
            # å°å…©å€‹é»é€²è¡Œæ—‹è½‰è®Šæ›
            def rotate_point(y, x, center_y, center_x, cos_a, sin_a):
                # å°‡åº§æ¨™ç§»è‡³åŸé»
                rel_x = x - center_x
                rel_y = y - center_y
                # é€²è¡Œæ—‹è½‰ï¼ˆæ³¨æ„åº§æ¨™ç³»çµ±ï¼šå½±åƒ y è»¸å‘ä¸‹ï¼‰
                new_x = rel_x * cos_a + rel_y * sin_a
                new_y = -rel_x * sin_a + rel_y * cos_a
                # ç§»å›åŸä½ç½®
                return new_y + center_y, new_x + center_x
            
            point1 = rotate_point(point1[0], point1[1], center_y, center_x, cos_angle, sin_angle)
            point2 = rotate_point(point2[0], point2[1], center_y, center_x, cos_angle, sin_angle)
            
            # æ—‹è½‰é©—ç®—
            distance = abs(point1[0] - point2[0])
            difference_ratio = abs(distance - original_euclidean_distance) / original_euclidean_distance
            difference_percent = difference_ratio * 100
            
            if difference_percent > 10.0:
                print(f"    âš ï¸  æ—‹è½‰é©—ç®—è­¦å‘Š: å·®ç•° {difference_percent:.1f}% (æª”æ¡ˆ: {file})")
        else:
            # æ²’æœ‰æ—‹è½‰æ™‚ï¼Œä½¿ç”¨åŸå§‹å‚ç›´è·é›¢
            distance = abs(point1_original[0] - point2_original[0])
        
        # æœ€çµ‚ä½¿ç”¨çš„å‚ç›´æ–¹å‘è·é›¢
        final_distance = abs(point1[0] - point2[0])
        
        print(f"  âœ… å‚ç›´è·é›¢: {final_distance:.2f} åƒç´ ")
        
        if video_name in new_scale_data:
            new_scale_data[video_name].append(final_distance)
        else:
            new_scale_data[video_name] = [final_distance]

# è¨ˆç®—å¹³å‡å€¼ä¸¦æ›´æ–°å¿«å–
for video_name, distances in new_scale_data.items():
    scale_cache[video_name] = np.mean(distances)
    print(f"ğŸ“Š {video_name}: å¹³å‡æ¯”ä¾‹å°º {scale_cache[video_name]:.4f} åƒç´ ")

# å„²å­˜æ›´æ–°çš„å¿«å–
if new_scale_data:
    cache_info = {
        'last_updated': datetime.datetime.now().isoformat(),
        'total_videos': len(scale_cache),
        'directory_hash': generate_scale_images_hash(scale_images_dir),
        'newly_processed': len(new_scale_data)
    }
    save_scale_cache(scale_cache, cache_info)

# è¨­å®šæœ€çµ‚çš„æ¯”ä¾‹å°ºå­—å…¸ä¾›ä¸»ç¨‹å¼ä½¿ç”¨
video_scale_dict = scale_cache

print(f"\nğŸ“Š æ¯”ä¾‹å°ºè™•ç†å®Œæˆï¼Œå…±è™•ç† {len(video_scale_dict)} å€‹å½±ç‰‡çš„æ¯”ä¾‹å°ºè³‡æ–™:")
for video, scale in video_scale_dict.items():
    print(f"  {video}: {scale:.2f} åƒç´ ")

print(f"\nğŸ¬ é–‹å§‹è™•ç†å½±ç‰‡...")

for root, folder, files in os.walk(os.path.join(DATA_FOLDER, 'lifts','data')):
    for file in files:
        print(f"\nğŸ¥ æ­£åœ¨è™•ç†å½±ç‰‡: {file}")
        scan(os.path.join(root, file), file)
        print(f"âœ… å½±ç‰‡è™•ç†å®Œæˆ: {file}")

print(f"\nğŸ‰ æ‰€æœ‰å½±ç‰‡è™•ç†å®Œæˆï¼")


# scan(os.path.join(DATA_FOLDER, "lifts", "data", "2.mp4"), "2.mp4")

